---
title: 'Visi√≥n 5: Procesamiento de imag√©nes'
description: ''
pubDate: 'Nov 08 2022'
heroImage: '/placeholder-hero.jpg'
url: '/ia'
---

## Espacio de color CIELAB

El espacio de color LAB fue desarrollado en 1940 por Richard Hunter para emular la percepci√≥n humana del color. Posteriormente, la Comisi√≥n Internacional de Iluminaci√≥n (CIE) lo estandariz√≥ como CIELAB.

Este modelo tiene tres canales:

- **L (Lightness):** Indica la luminosidad, de 0 (negro) a 100 (blanco).
- **A:** Representa la escala rojo-verde. Valores negativos indican verde, positivos indican rojo. Rango: -128 a 127.
- **B:** Representa la escala azul-amarillo. Valores negativos indican azul, positivos indican amarillo. Rango: -128 a 127.

<!--
![CIELAB](https://cdn.educalms.com/YzFjeHYlMkJlVEcxaEM3QVdIaE5HajhRJTNEJTNE-1721386079.png?Expires=1740020431&Signature=kW5S7-SgzhZFWCrjwjdyB7GozA0FEpxMf7gr8blomrU-JUzqcE4sRhuS1NxdL5SE7lNYHava5HkSq~E1SCamvMtDDD2Ey968ON4SOFETSzaTU2RYJPKggLVPLeF8~-jBn-2TSjBp0ouL4X~qgjWTQ8YlSF8k~9RqFCGuopWWL8eU94G5Gjy6195h~fejv7o93dPyvHUKU40v-nW4OLMUfv2ie22rLdhBbGnPUW5a6pBlsIjfEaSB1hl9r9MFpSnkvxfm~A0nioVOxcJMuI~ZfzhnbzEEWYRnVARnK0fdANYEdwTwO13Dj6jwZf6fIWRMMJD-ReBl~~Wkyu5OSMAfYg__&Key-Pair-Id=K2XVTQ1784SQT0)   -->

---

## Espacio de color HSV

El modelo **HSV (Hue, Saturation, Value)** se dise√±√≥ como una alternativa a **RGB**, ya que refleja mejor la forma en que el ojo humano percibe los colores. En lugar de procesar tres canales de color, el cerebro reacciona principalmente a la saturaci√≥n y el brillo.

**Componentes:**

- **H (Hue ‚Äì Tono):** Se mide en grados dentro de un c√≠rculo de 360¬∞.
  - Rojo: 0¬∞ - 60¬∞
  - Amarillo: 61¬∞ - 120¬∞
  - Verde: 121¬∞ - 180¬∞
  - Cian: 181¬∞ - 240¬∞
  - Azul: 241¬∞ - 300¬∞
  - Magenta: 301¬∞ - 360¬∞
- **S (Saturation ‚Äì Saturaci√≥n):** Indica la cantidad de gris en el color.
  - 100%: Color puro.
  - 0%: Gris puro.
- **V (Value ‚Äì Valor):** Define la intensidad del color.
  - 0%: Negro.
  - 100%: Color con m√°xima intensidad.

<!-- ![HSV](https://cdn.educalms.com/YjJuNXhGNHlQeiUyQkZMaG8lMkJ0Z0c5a2clM0QlM0Q=-1721386074.png?Expires=1740013245&Signature=azcrPnOgIxPeKxmgeFCKFRqPfSss4b1PeiyfakDO6ZqrhklLRfkjGWWL7iszmvUCLr9aOVre1761yAcO8LYsS6LF1c2k6vgOxJnrTA2VUeZPCBUMhQtMeGvTXFLIM70bFkSzVAy1uPX6Ityc-QP3K0s95awdt8QxC6SOUaeTiUAuHVVM-mrnNAZgwFEGvWoroqDmujObBW4DSna0xTa2WIPdYAlckV8Km3uD5G~3M7qVTG3kA7mMCf4JCiM~z3biADnh2ojilfF7V7Z17UJEzDwYdhUw8ek3ZepAd5o7e6IUwB-f8jbwVK-mi11MLklfJFfHQ-xWDOIRyTe2K05TEw__&Key-Pair-Id=K2XVTQ1784SQT0)
 -->

## Representaci√≥n de im√°genes

### Histograma de intensidades

Le preguntamos a cada p√≠xel qu√© intensidad tiene (valor num√©rico). Con esto sacamos el histograma y podemos emplearlo para diferenciar im√°genes oscuras o con fondo negro de im√°genes claras o con fondo blanco de forma autom√°tica.

---

## Transformaci√≥n de im√°genes

Manipular las im√°genes antes de que ingresen al modelo de inteligencia artificial es un punto importante.

### Transformaciones en intensidad

Manipulan el contraste y el gamma de la imagen.

### Transformaciones geom√©tricas

Modifican la relaci√≥n espacial entre los distintos p√≠xeles de la imagen. Deformando, rotando o comprimiendo ciertas zonas de la imagen, obtenemos im√°genes transformadas desde las originales.

Esto se encuentra dentro del "Preprocesado de imagen".

---

Captura -> Preprocesado de imagen -> Extracci√≥n de features -> Aplicaci√≥n del objetivo -> Decisi√≥n y reporte

---

## Transformaciones en intensidad

Son las que realizan los softwares de edici√≥n fotogr√°fica cuando manipulamos el contraste, el brillo y el gamma, entre otros.

### 1. Negativos

Es el m√°s sencillo y se trabaja en escala de grises. La idea es que los m√°ximos se conviertan en m√≠nimos y viceversa.

Con OpenCV se usa la funci√≥n `cv2.bitwise_not(img)`, que niega los p√≠xeles para obtener su valor opuesto.

### 2. Correcci√≥n de gamma

Emplea operaciones lineales. Si no aplicamos correcci√≥n gamma, estamos malgastando los p√≠xeles m√°s brillantes y m√°s oscuros de la imagen, en los que el ser humano no percibe nada, mientras maximizamos la informaci√≥n almacenada en los valores intermedios de intensidad.

Nos permite observar correctamente ciertos detalles de las im√°genes que pasan desapercibidos para el inter√©s de nuestro modelo.

### 3. Mejora del contraste

- **Ecualizaci√≥n del histograma**: Se emplea cuando hay poca variaci√≥n de intensidad entre los p√≠xeles (todos muy claros o todos muy oscuros). Si todos los p√≠xeles tienen valores entre 0 y 20, entonces 235 valores no se usan, lo que podr√≠a ayudarnos a distinguir mejor los detalles de la imagen.

- **Ecualizaci√≥n local del histograma**: Dividimos la imagen en una serie de regiones llamadas teselas o "tiles". En cada una de estas regiones ejecutamos la "ecualizaci√≥n del histograma" para no afectar al resto. Luego de ecualizar todas las regiones, se aplica el algoritmo de interpolaci√≥n para evitar bordes artificiales, llamados "artifacts".

- **Umbralizaci√≥n (thresholding)**: Segmenta im√°genes y cae en la extracci√≥n de caracter√≠sticas. Consiste en etiquetar cada p√≠xel de la imagen para comprender su tipolog√≠a. De acuerdo con el thresholding, pintaremos los p√≠xeles de blanco o negro.

Se puede configurar de forma autom√°tica:

1. **Umbralizado basado en histograma**: Se usa la forma del histograma para decidir puntos cr√≠ticos como picos o valles.
2. **Umbralizado global autom√°tico**: Selecciona el valor medio entre la intensidad m√°xima y la m√≠nima para seleccionar el umbral de divisi√≥n.
3. **Umbralizado de Otsu**: Maximiza la varianza entre la clase 0 y la clase 1.
4. **Umbralizado local adaptativo**: Cada imagen se divide en peque√±as subregiones para umbralizar cada una por separado.

## Transformaciones geom√©tricas

Manipulan el espacio entre p√≠xeles, modificando la ubicaci√≥n de cada p√≠xel. No son muy empleadas en visi√≥n artificial.

- **Distancia entre p√≠xeles**: Si la distancia entre p√≠xeles se mantiene, estamos tratando con transformaciones geom√©tricas r√≠gidas. Estas incluyen:

  - Traslaci√≥n
  - Rotaci√≥n

- **√Ångulos entre p√≠xeles**: Son transformaciones geom√©tricas semejantes.

  - **Escalado**: Ampl√≠a o reduce la imagen, generando o destruyendo p√≠xeles, pero manteniendo la relaci√≥n de aspecto original entre ellos.
  - **Afinidad entre p√≠xeles**: Deforma las im√°genes, pero mantiene la ubicaci√≥n relativa de los elementos, estir√°ndolas o achat√°ndolas.

- **Colinealidad entre p√≠xeles**: Cambia la perspectiva de la imagen.
  - **Transformaci√≥n proyectiva**: Se usa para rectificar o deformar en funci√≥n de un punto de fuga.

## Operaciones morfol√≥gicas

Se aplican a im√°genes binarias y monocrom√°ticas sobre formas y estructuras. Nos ayudan a hacer los objetos m√°s grandes o peque√±os, aumentar o reducir el espacio entre ellos.

Las operaciones morfol√≥gicas emplean un _structuring element_ para definir la zona analizada alrededor de cada p√≠xel y aplicar la funci√≥n morfol√≥gica deseada.

1. **Erosi√≥n**: Las zonas con p√≠xeles negros (0) se convierten en negro (0). Se usa un _structuring element_ con la forma deseada (cuadrada, circular, etc.).

2. **Dilataci√≥n**: Contraria a la erosi√≥n. Si hay un p√≠xel blanco, todos los p√≠xeles en la zona se convierten en blanco.

3. **Apertura (open)**: Erosi√≥n seguida de dilataci√≥n. Elimina las zonas peque√±as, pero luego agranda las que se han mantenido.

4. **Cierre (close)**: Contrario a la apertura. Aplica dilataci√≥n seguida de erosi√≥n, cerrando agujeros en los objetos y reduciendo los peque√±os puntos negros que pueden entorpecer los algoritmos.

---

# Filtrado: Desenfoque, Nitidez y Suavizado

Los **kernels de convoluci√≥n** aplican operaciones matem√°ticas sobre una imagen para lograr efectos como **desenfoque, suavizado o aumento de nitidez**.

Convolucionar un kernel implica multiplicar una matriz \( M \times N \) por los p√≠xeles de la imagen mediante una **ventana deslizante** (_sliding window_).

<!-- ![Ejemplo de convoluci√≥n](https://cdn.educalms.com/MWRMZmpMcTl5ZXY1dzNSSVBjbmExQSUzRCUzRA==-1721386093.png?Expires=1740092976&Signature=dKtVF5dksYmLgBpn~Te45hBfhE-h11EX4js6EyMe5lSmMsvmJXqb0B8N-HU9FxkhO-2fLMPCYG02cGxixX9jHRp25TJUuU7Msd66577F7VROTACpEnJas5IxM5jDKMLecN6YBTP1xp-OV5ys8plm4tf8ckm9Te8KSKs9VtPRZO8rZLLesfE6DJiW2NEk6~e-QEEvTzNlehbCN-lSHlIp-rnwgJ~1k6RiRY8zvXlOoRFYBxQYDNhYEenN81vOP8E-uiS42SorQDMzIX-fR2KNMwG1Skrpt8xBAGMA3ndCL5vy~Gb-VOncPLxfVQPtlQEMEXaXPC7ckMxQc4OuTtcUsA__&Key-Pair-Id=K2XVTQ1784SQT0) -->

Un **kernel 3√ó3** se multiplica por una regi√≥n de **3√ó3 p√≠xeles** en la imagen original (_input_), generando un nuevo p√≠xel en la imagen de salida (_output_). Dependiendo del kernel utilizado, el resultado ser√° **suavizado, nitidez o filtrado**.

### 1Ô∏è‚É£ Desenfoque (_Blurring_) y Eliminaci√≥n de Ruido (_Denoising_)

üîπ **Averaging Blurring**  
El kernel contiene valores iguales, promediando los p√≠xeles para suavizar la imagen.

<!-- ![Ejemplo de averaging blurring](https://cdn.educalms.com/U01aeVlOTnl1bVVTQlpJeHRBazdvQSUzRCUzRA==-1721386094.png?Expires=1740109861&Signature=BflBjvnWk7xyJGDpyMM~Uqg1PaF1AvFGhpQn1pYQJX9ifuQEqpakjPmbfZqPm7pf-d-EhQVeS9mOd7fCcKPXfdsASugg5J7QvnKYEMuiRAhPQpdEIFSMgZOq2ZaC2ab5qNtUhrX4yrOJNFfy8joGMez7iYnxPvYVdK6~G9IQA5t4rKrwpBX-QeQZiY2NL9YgW4jp5~ETy8rrGGQvxZDtg4ZUKX8rad~5TNSKjAmDkdlEY-bNGeVooMdc6Ij2s7xR8t902kkFI3eE7OAmYdZNbXVXc7eSgmWWSpgvaUUmlp~lAd0bkRrO2qYJYG8trr16bLAg6IkhdYd1xcqArPNKLg__&Key-Pair-Id=K2XVTQ1784SQT0)   -->

üîπ **Gaussian Blurring**  
Asigna mayor peso al p√≠xel central, luego a los adyacentes y menor a las esquinas.

<!-- ![Ejemplo de Gaussian blurring](https://cdn.educalms.com/WVBKR29VcERvNTJQQVBINTdYQVJMUSUzRCUzRA==-1721386095.png?Expires=1740109861&Signature=FWf4Mly7oRvwLc4fY5onaqp5ofBLXlIeAAidENMPlGIhwKBuDxx98j~i0f3zsIIUtW82zCTicakwCV33-Sq7g6V5CkxdRQB31xKfjGDy3jNFnOAYGURpJe23nkJCPUjhWnm3iFXcpb4QpBzy7XstHhTlVg9~OH-TTyFWWu0qKO62vFAh2EPCvFnEzwYrbzRjMtWCqnDEGXh812ZnGL5jqk4AsYcUDkCXqo9auNRpr7UBfukHH0FVBAUxtMDsj3K24fHb-KNf0SB1IyJXkefrIptqyGeFWBzK-4HPVX~OsKU9Cu2umZfL-2KL0FKzPhBqMkOrmmC0PcxIrmc4kKr2oQ__&Key-Pair-Id=K2XVTQ1784SQT0)   -->

üîπ **Median Blurring**  
Sustituye cada p√≠xel por la mediana de los valores en su vecindad.

<!-- ![Ejemplo de Median Blurring](https://cdn.educalms.com/eHdmYkExczJBRVp4YzQ0QkJrYTYzUSUzRCUzRA==-1721386096.png?Expires=1740109861&Signature=uoJvnOJF5XPNuQzabVEi2qTNy1Q3WfTRXVqLcTKpHaKrGIxAe9BL7LNALjHhrc3M6fqnMo56IiMptxhWVaenkauaTRNYZ7vD37-svWlzAQqcYRRFZagDiOVozoGPx1GosYqMPRc2SzyY9PLxlxUPc5aGTCpaMItkJ5yqpDEmD5PjY05aDUdCpecLYwrUW6Lf4xTs7g6ZZoCqbKe1TkH8bSyacgL75nm1sMdNZISoTvq0EqVlAH4n4rBrvtfE38AaDhu~yyu0jtV4TSy5f0-Ua5sTwNSQ~1d4L~3ptjZE4Op2glntL6lhyK1oLnL-tdqPeZbPlMQH905f6hFGm3qfgA__&Key-Pair-Id=K2XVTQ1784SQT0)   -->

### 2Ô∏è‚É£ Aumento de Nitidez (_Sharpening_)

üîπ Realza los bordes y el contraste en la imagen.

<!-- ![Ejemplo de sharpening](https://cdn.educalms.com/SEE4VWVWRFVMQ2M5VW85TmRMWU44QSUzRCUzRA==-1721386097.png?Expires=1740110532&Signature=C24IhVMXON7shEtV9RybAQQnNzfNVvKc-P4J-uTxMSopQb6ans8iNvRHjO4V6TOW5KjhvPMpsUkaAuBrGNlSH8BCO6iOEnLU4cygJkt2Vs0OvL-v4VHJD0QmW2JAnfGlOCBaQVJZPQ9ixk88dFfMYdzxKhen9czIwChDZRzXzS1IHYXzP2EH-7jM9zMWFjwsyjpznw8gKLnYraMWzmo48dqts6aomwU4fFtghXOSxvU8ef4X5BP7rHwC4YP45EROBKhJRa847eznZmMrH-RxoAyn1IvWU6WufY8iCwZTO8AadeMD5oAcqp9KIlUh3MvlUjAq7I9XyIqBGPIqMVao5g__&Key-Pair-Id=K2XVTQ1784SQT0)
 -->

---

## Detecci√≥n de Contornos, Bordes, Rectas y Esquinas

La extracci√≥n de caracter√≠sticas en im√°genes es fundamental para identificar formas, estructuras, objetos y cambios de iluminaci√≥n. Entre estas caracter√≠sticas, los bordes son clave, ya que permiten definir la tipolog√≠a y ubicaci√≥n de los objetos.

Un borde es una regi√≥n en la que la intensidad cambia abruptamente, presentando discontinuidades. Para detectarlos, se pueden utilizar t√©cnicas como convoluciones y el algoritmo de Canny.

### Detecci√≥n de Bordes con Kernels

Se pueden aplicar filtros para detectar bordes en diferentes direcciones:

- **Bordes verticales:** Se analizan p√≠xeles contiguos en direcci√≥n vertical.
- **Bordes horizontales:** Se examinan p√≠xeles en una l√≠nea horizontal.
- **Bordes diagonales:** Se comparan p√≠xeles en diagonales opuestas.

Los tres kernels m√°s utilizados para esta tarea son:

- **Sobel** y **Prewitt**: Identifican los m√°ximos y m√≠nimos de la intensidad en cada eje.
- **Laplaciano**: Busca bordes en ambas dimensiones simult√°neamente, aunque es sensible al ruido. Para optimizar su rendimiento, se recomienda aplicar primero filtros como el Gaussiano y el Median Filter.

### Detecci√≥n de Bordes con Canny

El algoritmo de Canny sigue varios pasos antes de identificar los bordes:

1. Aplicaci√≥n de un filtro de reducci√≥n de ruido mediante un filtro gaussiano con kernel 5x5, seguido de Sobel.
2. Uso del algoritmo **Non-Maximum Suppression** para refinar la detecci√≥n de bordes.
3. Aplicaci√≥n de **Hysteresis Thresholding** para seleccionar √∫nicamente los bordes con valores dentro de un rango definido.

### Detecci√≥n de Contornos

Un contorno es un borde cerrado y se extrae considerando la jerarqu√≠a entre los elementos de la imagen. Existen dos m√©todos principales:

1. **Sin aproximaci√≥n en cadena:** Se agrupan bordes cercanos con intensidades similares.
2. **Con aproximaci√≥n en cadena:** Se reducen los contornos a sus puntos clave, lo que optimiza el procesamiento.

### Detecci√≥n de Rectas y C√≠rculos

El m√©todo m√°s utilizado para detectar rectas es la **Transformada de Hough**, desarrollada en 1962. Funciona sobre im√°genes de profundidad 1 bit y eval√∫a todas las rectas posibles que pasan por un punto, compar√°ndolas con los dem√°s puntos para identificar las l√≠neas m√°s probables.

### Detecci√≥n de Esquinas

Las esquinas ayudan a delimitar objetos en im√°genes y son fundamentales para el seguimiento en videos, ya que permanecen invariantes ante cambios de tama√±o, intensidad y posici√≥n.

El m√©todo de **Harris**, desarrollado en 1988 por Chris Harris y Mike Stephens, clasifica las regiones de la imagen en:

1. **Zonas planas:** Sin cambios significativos de intensidad.
2. **Bordes:** Cambios de intensidad en un solo eje (vertical u horizontal), detectados con Sobel.
3. **Esquinas:** Variaciones de intensidad en ambas direcciones (X e Y).

<!-- ![Ejemplo de detecci√≥n de esquinas](https://cdn.educalms.com/MWtWcW02RTRXWEtmNkpZMmFTRnVsdyUzRCUzRA==-1721386111.png?Expires=1740117365&Signature=NZgFK2mAAVSUQeoHiS6i6g-IhoPNorMcl1aRKoeAzRuOAcTIpp1z-izLBp8jJwcjSDoNGau8aAHx9UJpYgkdOTFf-7bYWA38qTRDNW4zMyVbDm3Q1~0YyHQRElUwAt-eBgbwjmgSUCZwxBh7uLt2ztcH7hD9vGS7dKF9sXC~b61q0OjwYdHmCNd19Rzv2M70yO6pLoTyfP0C-ciD-wF86YWoNB-DDZQOHqWxA12VswH0Xi0J8MBaZGIpxtf1S7MqAJ0ucV1ZFkD92XHBJkV4JD8aY~4aZhMAbHCLDqajc7PuL3sDCI8qUxo4auOubPYYB~-c05ths0ztIg2FXbephw__&Key-Pair-Id=K2XVTQ1784SQT0)
 -->

En 1994, el m√©todo fue mejorado con el algoritmo **Shi-Tomasi** (_Good Features To Track_), que identifica esquinas relevantes para el seguimiento en videos. A diferencia de Harris, este algoritmo selecciona caracter√≠sticas estables ante cambios de rotaci√≥n y escala.
