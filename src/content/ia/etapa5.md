---
title: 'ETAPA 5: La Gran Expansión de la IA (1994 - 2011)'
description: 'La inteligencia artificial demostró lo que en ciertos momentos de la historia parecía imposible: ser útil y, al mismo tiempo, realmente inteligente.'
pubDate: 'Nov 08 2022'
heroImage: '/placeholder-hero.jpg'
url: '/ia'
---

La inteligencia artificial demostró lo que en ciertos momentos de la historia parecía imposible: ser útil y, al mismo tiempo, realmente inteligente.

Durante este periodo, algunas empresas e investigadores evitaron el término "Inteligencia Artificial", empleando nombres como "informática avanzada", "sistemas cognitivos" o "inteligencia computacional" para evitar el estigma asociado a los fracasos anteriores en el campo.

## Avances en Vehículos Autónomos

En 1994, Daimler-Benz probó su sistema VaMP y Vita-2, logrando recorrer más de 1.000 km en autopistas de París con tráfico real y mínima intervención humana a velocidades de hasta 130 km/h. En 1995, el Navlab de Carnegie Mellon recorrió 5.000 km de forma autónoma, con una red neuronal que analizaba imágenes de una cámara para controlar el volante, mientras que aceleración, freno y cambios seguían en manos humanas.

## A.L.I.C.E. y Deep Blue

En 1995, Richard Wallace creó A.L.I.C.E., un chatbot basado en respuestas predefinidas y heurísticas, aunque incapaz de superar el Test de Turing.

En 1997, IBM desarrolló Deep Blue, el primer ordenador en derrotar a un campeón mundial de ajedrez. Tras perder 4-2 contra Garry Kasparov en 1996, IBM mejoró su sistema y, en 1997, venció. Deep Blue usaba fuerza bruta, analizando hasta 20 movimientos en profundidad basándose en partidas anteriores.

## Avances en Redes Neuronales y Aprendizaje Automático

El aprendizaje automático y las redes neuronales cobraron protagonismo:

- Geoffrey Hinton propuso el algoritmo de _backpropagation_.
- John Hopfield introdujo sus redes neuronales.
- Yann LeCun desarrolló las redes neuronales convolucionales, aplicándolas a la clasificación de códigos postales.
- En 1997, Sepp Hochreiter y Jürgen Schmidhuber presentaron las _Long Short-Term Memory_ (LSTM), una mejora para redes neuronales recurrentes que permitió el procesamiento eficiente de secuencias de datos.

## Aplicaciones Tangibles

La IA comenzó a integrarse en productos reales:

- **2000**: Cynthia Breazeal desarrolló Kismet, un robot capaz de reconocer y simular emociones humanas.
- **2001**: Paul Viola y Michael Jones presentaron el algoritmo Viola-Jones para detección facial en tiempo real.
- **2002**: I-Robot lanzó el primer aspirador autónomo comercialmente exitoso.
- **2004**: Los rovers Spirit y Opportunity de la NASA navegaron Marte sin intervención humana.

## Vehículos Autónomos en Competencia

En 2004, DARPA organizó el _Grand Challenge_, un certamen de vehículos autónomos con un premio de un millón de dólares. En 2005, el vehículo _STANLEY_ de Stanford ganó la competición tras recorrer 212 km en 6 horas y 54 minutos, utilizando LIDAR, GPS y aprendizaje automático.

## Boston Dynamics y Machine Reading

En 2005, Boston Dynamics construyó _BigDog_, un robot cuadrúpedo diseñado para acompañar a soldados en terrenos difíciles. En 2006, se introdujo el concepto de _Machine Reading_, la capacidad de una máquina para comprender texto como lo haría un ser humano.

## ImageNet y la Revolución del Deep Learning

En 2007, Fei-Fei Li creó ImageNet, una base de datos con 14 millones de imágenes etiquetadas, fundamental para el desarrollo del _Deep Learning_. En 2009, Alex Berg propuso agregar información de localización de objetos dentro de las imágenes, lo que llevó al _ImageNet Large Scale Visual Recognition Challenge (ILSVRC)_, un hito en la visión artificial.

## Avances en Procesamiento del Lenguaje Natural (NLP)

- **2008**: Google mejoró la precisión del reconocimiento de voz del 80% al 92% mediante redes neuronales masivamente paralelas.
- **2010**: Microsoft lanzó Kinect para Xbox 360, revolucionando la captura de movimiento 3D y el reconocimiento facial.
- **2011**: IBM desarrolló _Watson_, que ganó el concurso _Jeopardy!_ gracias a su capacidad de comprender lenguaje natural y resolver preguntas complejas.
- **2011**: Apple presentó Siri, un asistente virtual basado en NLP.

## Hacia una Nueva Era

En 2011, la IA alcanzó hitos en reconocimiento de patrones, superando la capacidad humana en varias tareas como el reconocimiento de dígitos manuscritos (99,73% de precisión) y señales de tráfico (99,46%).

Finalmente, en 2012, Geoffrey Hinton marcó el inicio de una nueva era en la inteligencia artificial, dando paso al _Deep Learning_ moderno.

---

## **Resumen (1994 - 2011)**

**1995** - ALICE chatbot con capacidad de aprender conversaciónes que mantiene gracias a los avances en procesamiento y almacenamiento

**1997** - Deep Blue, completando un objetivo que perseguia la IA desde sus inicios. Se publican las LSTM.

**2000** - Kismet, se presenta Kismet el primer robot capaz de reconocer y simular emociones humanas, sistemas basicos de NLP y vision artificial.

**2001** - Viola Y Jones solucionan el problema del reconocimiento facial en tiempo real gracias a su metodo para el reconocimineto de objetos basado en Haar features.

**2002** - El primer robot domestico llega al mercado: Roomba limpia el suelo de una vivienda de forma autonomo gracias a sus sensores de algoritmos de guiado.

**2004** - La NASA despliega Spirit y Opportunity autonomos que emplean vision artificial para seleccionar los caminos menos accidentados.

**2007** - Fei Fei Lei publica la base de imagenes etiquetas mas grande del mudno, llamada ImageNet. Permitira a investigadores entrenar y evaluar sus modelos de clasificación y detección de objetos dentro de la visión aritificial.

**2008** - Google lanza speech to text en IPhone. obteniendo precisión mayor al 80%.

**2010** - Microsoft lanza Kinect, con la capacidad de estimar la pose humana mediante un algoritmo novedoso basado en cámaras a color, infrarrojos y micrófonos.

**2011** - La IA de IBM watson vence en Jeopardy! ejecutando redes neuronales NLP, para comprender las preguntas y buscar repuestas. Apple lanza Siri mejorando speech to text, NLP y text to speech conocidos hasta el momento Nunca se liberó el algoritmo.
